# 🚀 快速入门指南

## 一、安装依赖

```bash
# 安装Python依赖
pip3 install -r requirements.txt
```

## 二、启动Web界面

### macOS/Linux
```bash
./start_web.sh
```

### Windows
```bash
start_web.bat
```

### 或直接运行
```bash
python3 app.py
```

## 三、使用Web界面

1. 打开浏览器访问：`http://localhost:8887`
2. 输入Twitter用户名（不含@符号）
3. 设置爬取数量（建议从少量开始测试）
4. 选择保存格式
5. 点击"开始爬取"
6. 等待完成后预览或下载数据

## 四、Web界面功能

### 🎯 主要功能
- **智能爬取**：自动模拟真实浏览行为
- **实时进度**：可视化显示爬取进度
- **数据预览**：在线查看推文内容（支持CSV和JSON）
- **一键下载**：支持CSV和JSON格式（默认CSV）
- **历史记录**：管理所有爬取的数据
- **CSV优先**：默认保存为CSV格式，Excel友好

### 📊 界面特色
- 现代化设计，流畅动画
- 实时状态更新
- 响应式布局
- 移动端友好

## 五、命令行使用（可选）

如果你喜欢命令行：

```bash
python3 twitter_scraper.py
```

按提示输入参数即可。

## 六、注意事项

⚠️ **重要提示**：
- 首次运行会自动下载ChromeDriver（需要网络）
- 确保已安装Chrome浏览器
- 建议从少量推文开始测试
- 请合理使用，遵守Twitter服务条款

## 七、常见问题

### Q: 页面打不开？
A: 检查8887端口是否被占用。如遇端口冲突，可修改app.py中的端口号（如改为3000、8000等）。

### Q: ChromeDriver错误？
A: 确保已安装Chrome浏览器，程序会自动下载驱动。

### Q: 爬取失败？
A: 检查用户名是否正确，网络是否稳定。

### Q: 数据在哪里？
A: 所有数据保存在`data/`目录中。

## 八、获取帮助

- 查看完整文档：`README.md`
- 检查项目结构：查看`data/`目录
- 历史记录：在Web界面的"历史记录"部分

---

**祝使用愉快！** 🎉

如有问题，请参考完整的README.md文档。

