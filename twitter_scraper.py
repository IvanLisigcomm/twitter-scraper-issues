#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Xï¼ˆæ¨ç‰¹ï¼‰æ¨æ–‡çˆ¬è™«ç¨‹åº
æ¨¡æ‹Ÿäººå·¥æµè§ˆè¡Œä¸ºï¼Œè·å–æŒ‡å®šç”¨æˆ·çš„æ¨æ–‡å†…å®¹
"""

import os
import json
import csv
import time
import random
import shutil
from datetime import datetime
from typing import List, Dict, Optional

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
from fake_useragent import UserAgent
from bs4 import BeautifulSoup


class TwitterScraper:
    """Xï¼ˆæ¨ç‰¹ï¼‰æ¨æ–‡çˆ¬è™«ç±»"""
    
    def __init__(self, headless: bool = False, delay_range: tuple = (2, 5), progress_callback=None, control_callback=None):
        """
        åˆå§‹åŒ–çˆ¬è™«
        
        Args:
            headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
            delay_range: éšæœºå»¶è¿ŸèŒƒå›´ï¼ˆç§’ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥å— (current, total, message) å‚æ•°
            control_callback: æ§åˆ¶å›è°ƒå‡½æ•°ï¼Œè¿”å› (is_paused, is_cancelled) å…ƒç»„
        """
        self.headless = headless
        self.delay_range = delay_range
        self.driver = None
        self.tweets_data = []
        self.username = None  # ä¿å­˜å½“å‰çˆ¬å–çš„ç”¨æˆ·å
        self.progress_callback = progress_callback  # ä¿å­˜è¿›åº¦å›è°ƒå‡½æ•°
        self.control_callback = control_callback  # ä¿å­˜æ§åˆ¶å›è°ƒå‡½æ•°
        
        # åˆ›å»º data ç›®å½•
        self.data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data')
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            print(f"å·²åˆ›å»ºæ•°æ®ç›®å½•: {self.data_dir}")
        
    def setup_driver(self) -> webdriver.Chrome:
        """è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨"""
        print("æ­£åœ¨è®¾ç½®æµè§ˆå™¨é©±åŠ¨...")
        
        # Chromeé€‰é¡¹é…ç½®
        chrome_options = Options()
        
        if self.headless:
            chrome_options.add_argument('--headless')
            
        # åæ£€æµ‹é…ç½®
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # è®¾ç½®éšæœºUser-Agent
        ua = UserAgent()
        chrome_options.add_argument(f'--user-agent={ua.random}')
        
        # çª—å£å¤§å°
        chrome_options.add_argument('--window-size=1920,1080')
        
        # åˆ›å»ºé©±åŠ¨ - æ·»åŠ é‡è¯•æœºåˆ¶å’Œæ›´å¥½çš„é”™è¯¯å¤„ç†
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"å°è¯•å®‰è£… ChromeDriver (ç¬¬ {attempt + 1} æ¬¡)...")
                
                # ä½¿ç”¨ webdriver-manager å®‰è£… ChromeDriver
                driver_path = ChromeDriverManager().install()
                print(f"webdriver-manager è¿”å›è·¯å¾„: {driver_path}")
                
                # ä¿®å¤è·¯å¾„é—®é¢˜ - æŸ¥æ‰¾å®é™…çš„ chromedriver å¯æ‰§è¡Œæ–‡ä»¶
                if 'THIRD_PARTY_NOTICES' in driver_path or not driver_path.endswith('chromedriver'):
                    # åœ¨åŒä¸€ç›®å½•ä¸‹æŸ¥æ‰¾çœŸæ­£çš„ chromedriver æ–‡ä»¶
                    driver_dir = os.path.dirname(driver_path)
                    possible_paths = [
                        os.path.join(driver_dir, 'chromedriver'),
                        os.path.join(driver_dir, 'chromedriver-mac-arm64'),
                        os.path.join(driver_dir, 'chromedriver-mac-x64')
                    ]
                    
                    actual_driver_path = None
                    for path in possible_paths:
                        if os.path.exists(path):
                            # å…ˆè®¾ç½®æ‰§è¡Œæƒé™ï¼Œç„¶åæ£€æŸ¥
                            os.chmod(path, 0o755)
                            if os.access(path, os.X_OK):
                                actual_driver_path = path
                                break
                    
                    if actual_driver_path:
                        driver_path = actual_driver_path
                        print(f"æ‰¾åˆ°å®é™…çš„ ChromeDriver: {driver_path}")
                    else:
                        # åˆ—å‡ºç›®å½•å†…å®¹ä»¥è°ƒè¯•
                        print(f"ç›®å½•å†…å®¹: {os.listdir(driver_dir)}")
                        raise FileNotFoundError(f"åœ¨ {driver_dir} ä¸­æ‰¾ä¸åˆ°å¯æ‰§è¡Œçš„ chromedriver")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯æ‰§è¡Œ
                if not os.path.exists(driver_path):
                    raise FileNotFoundError(f"ChromeDriver æ–‡ä»¶ä¸å­˜åœ¨: {driver_path}")
                
                # åœ¨ macOS ä¸Šè®¾ç½®æ‰§è¡Œæƒé™
                if os.name != 'nt':  # é Windows ç³»ç»Ÿ
                    os.chmod(driver_path, 0o755)
                    print(f"å·²è®¾ç½® ChromeDriver æ‰§è¡Œæƒé™")
                
                service = Service(driver_path)
                driver = webdriver.Chrome(service=service, options=chrome_options)
                
                # æ‰§è¡Œåæ£€æµ‹è„šæœ¬
                driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
                
                self.driver = driver
                print("æµè§ˆå™¨é©±åŠ¨è®¾ç½®æˆåŠŸï¼")
                return driver
                
            except Exception as e:
                print(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    print("æ­£åœ¨é‡è¯•...")
                    # æ¸…ç†å¯èƒ½æŸåçš„ç¼“å­˜
                    import shutil
                    wdm_cache = os.path.expanduser("~/.wdm")
                    if os.path.exists(wdm_cache):
                        shutil.rmtree(wdm_cache)
                        print("å·²æ¸…ç† webdriver-manager ç¼“å­˜")
                    time.sleep(2)
                else:
                    print("æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥ Chrome æµè§ˆå™¨æ˜¯å¦å·²å®‰è£…")
                    raise e
    
    def random_delay(self, min_delay: Optional[float] = None, max_delay: Optional[float] = None):
        """éšæœºå»¶è¿Ÿ"""
        if min_delay is None:
            min_delay = self.delay_range[0]
        if max_delay is None:
            max_delay = self.delay_range[1]
            
        delay = random.uniform(min_delay, max_delay)
        print(f"ç­‰å¾… {delay:.2f} ç§’...")
        time.sleep(delay)
    
    def scroll_page(self, scrolls: int = 3):
        """æ¨¡æ‹Ÿæ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹"""
        print(f"æ­£åœ¨æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹...")
        
        for i in range(scrolls):
            # è·å–å½“å‰é¡µé¢é«˜åº¦
            last_height = self.driver.execute_script("return document.body.scrollHeight")
            
            # å°è¯•æ»šåŠ¨åˆ°æœ€åä¸€ä¸ªæ¨æ–‡å…ƒç´ çš„ä½ç½®
            try:
                last_tweet = self.driver.find_elements(By.CSS_SELECTOR, '[data-testid="tweet"]')[-1]
                self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", last_tweet)
                print(f"  æ»šåŠ¨ {i+1}/{scrolls}: æ»šåŠ¨åˆ°æœ€åä¸€ä¸ªæ¨æ–‡...")
            except:
                # å¦‚æœå¤±è´¥ï¼Œå°±æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                print(f"  æ»šåŠ¨ {i+1}/{scrolls}: æ»šåŠ¨åˆ°åº•éƒ¨...")
            
            # ç­‰å¾…æ–°å†…å®¹åŠ è½½
            self.random_delay(2, 4)
            
            # æ£€æŸ¥é¡µé¢é«˜åº¦æ˜¯å¦æ”¹å˜ï¼ˆè¯´æ˜åŠ è½½äº†æ–°å†…å®¹ï¼‰
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height > last_height:
                print(f"  âœ“ é¡µé¢é«˜åº¦å¢åŠ : {last_height} -> {new_height}")
            else:
                print(f"  âš  é¡µé¢é«˜åº¦æœªå˜åŒ–ï¼Œå¯èƒ½å·²åˆ°åº•éƒ¨")
            
            # ç¨å¾®å¾€å›æ»šä¸€ç‚¹ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆè¡Œä¸º
            if i < scrolls - 1:  # æœ€åä¸€æ¬¡ä¸å¾€å›æ»š
                self.driver.execute_script("window.scrollBy(0, -300);")
                self.random_delay(0.5, 1)
    
    def extract_tweet_data(self, tweet_element) -> Optional[Dict]:
        """ä»æ¨æ–‡å…ƒç´ ä¸­æå–æ•°æ®"""
        try:
            tweet_data = {}
            
            # è·å–æ¨æ–‡HTML
            tweet_html = tweet_element.get_attribute('innerHTML')
            soup = BeautifulSoup(tweet_html, 'html.parser')
            
            # æå–æ¨æ–‡æ–‡æœ¬
            text_elements = tweet_element.find_elements(By.CSS_SELECTOR, '[data-testid="tweetText"]')
            if text_elements:
                tweet_data['text'] = text_elements[0].text
            else:
                tweet_data['text'] = ""
            
            # æå–æ—¶é—´
            try:
                time_element = tweet_element.find_element(By.CSS_SELECTOR, 'time')
                tweet_data['timestamp'] = time_element.get_attribute('datetime')
                tweet_data['time_display'] = time_element.text
            except NoSuchElementException:
                tweet_data['timestamp'] = ""
                tweet_data['time_display'] = ""
            
            # æå–äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµã€è½¬å‘ã€è¯„è®ºï¼‰
            try:
                # ç‚¹èµæ•°
                like_elements = tweet_element.find_elements(By.CSS_SELECTOR, '[data-testid="like"]')
                if like_elements:
                    like_text = like_elements[0].get_attribute('aria-label') or "0"
                    tweet_data['likes'] = self.extract_number_from_text(like_text)
                else:
                    tweet_data['likes'] = 0
                
                # è½¬å‘æ•°
                retweet_elements = tweet_element.find_elements(By.CSS_SELECTOR, '[data-testid="retweet"]')
                if retweet_elements:
                    retweet_text = retweet_elements[0].get_attribute('aria-label') or "0"
                    tweet_data['retweets'] = self.extract_number_from_text(retweet_text)
                else:
                    tweet_data['retweets'] = 0
                
                # è¯„è®ºæ•°
                reply_elements = tweet_element.find_elements(By.CSS_SELECTOR, '[data-testid="reply"]')
                if reply_elements:
                    reply_text = reply_elements[0].get_attribute('aria-label') or "0"
                    tweet_data['replies'] = self.extract_number_from_text(reply_text)
                else:
                    tweet_data['replies'] = 0
                    
            except Exception as e:
                print(f"æå–äº’åŠ¨æ•°æ®æ—¶å‡ºé”™: {e}")
                tweet_data['likes'] = 0
                tweet_data['retweets'] = 0
                tweet_data['replies'] = 0
            
            # æ·»åŠ çˆ¬å–æ—¶é—´
            tweet_data['scraped_at'] = datetime.now().isoformat()
            
            return tweet_data
            
        except Exception as e:
            print(f"æå–æ¨æ–‡æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def extract_number_from_text(self, text: str) -> int:
        """ä»æ–‡æœ¬ä¸­æå–æ•°å­—"""
        try:
            # å¤„ç†åŒ…å«Kã€Mç­‰å•ä½çš„æ•°å­—
            text = text.lower().replace(',', '')
            if 'k' in text:
                number = float(text.replace('k', '')) * 1000
            elif 'm' in text:
                number = float(text.replace('m', '')) * 1000000
            else:
                # æå–çº¯æ•°å­—
                import re
                numbers = re.findall(r'\d+', text)
                number = int(numbers[0]) if numbers else 0
            return int(number)
        except:
            return 0
    
    def scrape_user_tweets(self, username: str, max_tweets: int = 50) -> List[Dict]:
        """
        çˆ¬å–æŒ‡å®šç”¨æˆ·çš„æ¨æ–‡
        
        Args:
            username: ç”¨æˆ·åï¼ˆä¸åŒ…å«@ç¬¦å·ï¼‰
            max_tweets: æœ€å¤§çˆ¬å–æ¨æ–‡æ•°é‡
            
        Returns:
            æ¨æ–‡æ•°æ®åˆ—è¡¨
        """
        if not self.driver:
            self.setup_driver()
        
        # ä¿å­˜ç”¨æˆ·åï¼Œç”¨äºåç»­æ–‡ä»¶å‘½å
        self.username = username
        
        print(f"å¼€å§‹çˆ¬å–ç”¨æˆ· @{username} çš„æ¨æ–‡...")
        
        # è®¿é—®ç”¨æˆ·ä¸»é¡µ
        url = f"https://x.com/{username}"
        print(f"æ­£åœ¨è®¿é—®: {url}")
        
        try:
            self.driver.get(url)
            self.random_delay(3, 6)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '[data-testid="tweet"]'))
            )
            
            # åˆå§‹åŒ–è¿›åº¦
            if self.progress_callback:
                self.progress_callback(0, max_tweets, "é¡µé¢åŠ è½½å®Œæˆï¼Œå¼€å§‹çˆ¬å–æ¨æ–‡...")
            
            tweets_collected = 0
            scroll_attempts = 0
            max_scroll_attempts = 20  # å¢åŠ æ»šåŠ¨æ¬¡æ•°
            no_new_tweets_count = 0  # è¿ç»­æ²¡æœ‰æ–°æ¨æ–‡çš„æ¬¡æ•°
            
            # ç”¨äºå»é‡çš„é›†åˆï¼ˆä½¿ç”¨timestamp+textçš„ç»„åˆï¼‰
            seen_tweets = set()
            
            while tweets_collected < max_tweets and scroll_attempts < max_scroll_attempts:
                # æ£€æŸ¥æ§åˆ¶æ ‡å¿—ï¼ˆæš‚åœ/å–æ¶ˆï¼‰
                if self.control_callback:
                    is_paused, is_cancelled = self.control_callback()
                    
                    # å¦‚æœè¢«å–æ¶ˆï¼Œç«‹å³é€€å‡º
                    if is_cancelled:
                        print("\nâŒ çˆ¬å–ä»»åŠ¡å·²è¢«å–æ¶ˆ")
                        break
                    
                    # å¦‚æœè¢«æš‚åœï¼Œç­‰å¾…æ¢å¤
                    while is_paused:
                        print("â¸ï¸  ä»»åŠ¡å·²æš‚åœï¼Œç­‰å¾…æ¢å¤...")
                        time.sleep(1)
                        is_paused, is_cancelled = self.control_callback()
                        if is_cancelled:
                            print("\nâŒ çˆ¬å–ä»»åŠ¡å·²è¢«å–æ¶ˆ")
                            break
                    
                    # å¦‚æœåœ¨æš‚åœæœŸé—´è¢«å–æ¶ˆï¼Œé€€å‡º
                    if is_cancelled:
                        break
                
                print(f"\n=== ç¬¬ {scroll_attempts + 1} è½®çˆ¬å– ===")
                print(f"å·²æ”¶é›† {tweets_collected}/{max_tweets} æ¡æ¨æ–‡")
                
                # æŸ¥æ‰¾æ¨æ–‡å…ƒç´ 
                tweet_elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-testid="tweet"]')
                print(f"å½“å‰é¡µé¢å…±æ‰¾åˆ° {len(tweet_elements)} ä¸ªæ¨æ–‡å…ƒç´ ")
                
                # æå–æ–°æ¨æ–‡ - éå†æ‰€æœ‰å…ƒç´ ï¼Œä½¿ç”¨å»é‡é›†åˆæ¥é¿å…é‡å¤
                new_tweets_in_this_scroll = 0
                for tweet_element in tweet_elements:
                    if tweets_collected >= max_tweets:
                        break
                        
                    tweet_data = self.extract_tweet_data(tweet_element)
                    if tweet_data and tweet_data['text'].strip():
                        # ä½¿ç”¨ timestamp + text ä½œä¸ºå”¯ä¸€æ ‡è¯†
                        tweet_id = f"{tweet_data.get('timestamp', '')}_{tweet_data['text']}"
                        
                        # æ£€æŸ¥æ˜¯å¦å·²ç»æ”¶é›†è¿‡è¿™æ¡æ¨æ–‡
                        if tweet_id not in seen_tweets:
                            seen_tweets.add(tweet_id)
                            self.tweets_data.append(tweet_data)
                            tweets_collected += 1
                            new_tweets_in_this_scroll += 1
                            print(f"  âœ“ æ–°æ¨æ–‡ #{tweets_collected}: {tweet_data['text'][:50]}...")
                            
                            # æ›´æ–°è¿›åº¦
                            if self.progress_callback:
                                self.progress_callback(tweets_collected, max_tweets, f"æ­£åœ¨çˆ¬å–æ¨æ–‡...å·²æ”¶é›† {tweets_collected}/{max_tweets} æ¡")
                
                print(f"â†’ æœ¬è½®æ”¶é›†åˆ° {new_tweets_in_this_scroll} æ¡æ–°æ¨æ–‡")
                
                # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œé€€å‡º
                if tweets_collected >= max_tweets:
                    print(f"\nâœ… å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {max_tweets} æ¡ï¼")
                    break
                
                # å¦‚æœè¿ç»­å¤šæ¬¡æ»šåŠ¨éƒ½æ²¡æœ‰æ–°æ¨æ–‡ï¼Œå¯èƒ½å·²ç»åˆ°åº•äº†
                if new_tweets_in_this_scroll == 0:
                    no_new_tweets_count += 1
                    print(f"âš ï¸  æœ¬è½®æ— æ–°æ¨æ–‡ï¼ˆè¿ç»­ {no_new_tweets_count} æ¬¡ï¼‰")
                    if no_new_tweets_count >= 3:
                        print("âŒ è¿ç»­3æ¬¡æ»šåŠ¨éƒ½æ²¡æœ‰æ–°æ¨æ–‡ï¼Œå¯èƒ½å·²ç»åˆ°è¾¾é¡µé¢åº•éƒ¨")
                        break
                else:
                    no_new_tweets_count = 0  # é‡ç½®è®¡æ•°å™¨
                
                # æ»šåŠ¨åŠ è½½æ›´å¤š
                print("\nğŸ“œ å¼€å§‹æ»šåŠ¨åŠ è½½æ›´å¤šæ¨æ–‡...")
                if self.progress_callback:
                    self.progress_callback(tweets_collected, max_tweets, f"æ­£åœ¨æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šæ¨æ–‡...å·²æ”¶é›† {tweets_collected}/{max_tweets} æ¡")
                
                prev_elements_count = len(tweet_elements)
                self.scroll_page(3)
                scroll_attempts += 1
                
                # æ»šåŠ¨åç­‰å¾…æ–°å†…å®¹åŠ è½½
                print("â³ ç­‰å¾…æ–°æ¨æ–‡åŠ è½½...")
                self.random_delay(3, 5)
                
                # æ£€æŸ¥æ˜¯å¦çœŸçš„åŠ è½½äº†æ–°å…ƒç´ 
                new_tweet_elements = self.driver.find_elements(By.CSS_SELECTOR, '[data-testid="tweet"]')
                if len(new_tweet_elements) > prev_elements_count:
                    print(f"âœ“ é¡µé¢å…ƒç´ å¢åŠ : {prev_elements_count} -> {len(new_tweet_elements)}")
                else:
                    print(f"âš ï¸  é¡µé¢å…ƒç´ æœªå¢åŠ ï¼Œä»ä¸º {len(new_tweet_elements)} ä¸ª")
            
            # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆä»æ–°åˆ°æ—§ï¼‰
            print("\næ­£åœ¨æŒ‰æ—¶é—´æ’åºæ¨æ–‡...")
            self.tweets_data.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
            
            print(f"çˆ¬å–å®Œæˆï¼å…±æ”¶é›†åˆ° {len(self.tweets_data)} æ¡æ¨æ–‡")
            return self.tweets_data
            
        except TimeoutException:
            print("é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå¯èƒ½ç”¨æˆ·ä¸å­˜åœ¨æˆ–ç½‘ç»œé—®é¢˜")
            return []
        except Exception as e:
            print(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return []
    
    def save_to_json(self, filename: str = None):
        """ä¿å­˜æ•°æ®ä¸ºJSONæ ¼å¼"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # ä½¿ç”¨ç”¨æˆ·å+æ—¶é—´æˆ³å‘½å
            username_part = self.username if self.username else "tweets"
            filename = f"{username_part}_{timestamp}.json"
        
        # ä¿å­˜åˆ° data ç›®å½•
        filepath = os.path.join(self.data_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.tweets_data, f, ensure_ascii=False, indent=2)
        
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def save_to_csv(self, filename: str = None):
        """ä¿å­˜æ•°æ®ä¸ºCSVæ ¼å¼"""
        if not self.tweets_data:
            print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return None
            
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # ä½¿ç”¨ç”¨æˆ·å+æ—¶é—´æˆ³å‘½å
            username_part = self.username if self.username else "tweets"
            filename = f"{username_part}_{timestamp}.csv"
        
        # ä¿å­˜åˆ° data ç›®å½•
        filepath = os.path.join(self.data_dir, filename)
        
        fieldnames = ['text', 'timestamp', 'time_display', 'likes', 'retweets', 'replies', 'scraped_at']
        
        # ä½¿ç”¨ utf-8-sig ç¼–ç ï¼Œæ·»åŠ  BOM æ ‡è®°ï¼Œè®© Excel èƒ½æ­£ç¡®è¯†åˆ« UTF-8 ç¼–ç 
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for tweet in self.tweets_data:
                writer.writerow(tweet)
        
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        print("æç¤º: CSV æ–‡ä»¶ä½¿ç”¨ UTF-8 BOM ç¼–ç ï¼Œå¯åœ¨ Excel ä¸­æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡")
        return filepath
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            print("æµè§ˆå™¨å·²å…³é—­")


def main():
    """ä¸»å‡½æ•°"""
    print("=== Xï¼ˆæ¨ç‰¹ï¼‰æ¨æ–‡çˆ¬è™«ç¨‹åº ===")
    print()
    
    # è·å–ç”¨æˆ·è¾“å…¥
    username = input("è¯·è¾“å…¥è¦çˆ¬å–çš„ç”¨æˆ·åï¼ˆä¸åŒ…å«@ç¬¦å·ï¼‰: ").strip()
    if not username:
        print("ç”¨æˆ·åä¸èƒ½ä¸ºç©ºï¼")
        return
    
    try:
        max_tweets = int(input("è¯·è¾“å…¥è¦çˆ¬å–çš„æ¨æ–‡æ•°é‡ï¼ˆé»˜è®¤50ï¼‰: ") or "50")
    except ValueError:
        max_tweets = 50
    
    headless_input = input("æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼Ÿ(y/N): ").strip().lower()
    headless = headless_input in ['y', 'yes', 'æ˜¯']
    
    save_format = input("é€‰æ‹©ä¿å­˜æ ¼å¼ (json/csv/bothï¼Œé»˜è®¤csv): ").strip().lower() or "csv"
    
    print()
    print("å¼€å§‹çˆ¬å–...")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    scraper = TwitterScraper(headless=headless)
    
    try:
        # çˆ¬å–æ¨æ–‡
        tweets = scraper.scrape_user_tweets(username, max_tweets)
        
        if tweets:
            print(f"\næˆåŠŸçˆ¬å–åˆ° {len(tweets)} æ¡æ¨æ–‡ï¼")
            
            # ä¿å­˜æ•°æ®
            if save_format in ['json', 'both']:
                scraper.save_to_json()
            
            if save_format in ['csv', 'both']:
                scraper.save_to_csv()
            
            print("\nçˆ¬å–ä»»åŠ¡å®Œæˆï¼")
        else:
            print("æ²¡æœ‰çˆ¬å–åˆ°ä»»ä½•æ¨æ–‡ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·åæ˜¯å¦æ­£ç¡®æˆ–ç½‘ç»œè¿æ¥")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­äº†ç¨‹åº")
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    finally:
        scraper.close()


if __name__ == "__main__":
    main()
